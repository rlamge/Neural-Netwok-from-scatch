{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biKcJVRzbFF1"
   },
   "source": [
    "# Dog Breed Classification using Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XynEVz9htI_K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "g_9qmlBfbIfi",
    "outputId": "29c302fb-0928-4817-e006-418cb3cc44e3"
   },
   "outputs": [],
   "source": [
    "DATADIR = \"C:/Dataset/Softmax\"\n",
    "CATEGORIES = [\"Beagle\",\"Chi\",\"Sam\"]\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "64cLOTyJqQ7-",
    "outputId": "24116110-fd31-415f-b2b6-ef257af3aae0"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def load_data():\n",
    "    for category in CATEGORIES:\n",
    "        \n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            \n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            new_array = cv2.resize(img_array,(img_size,img_size))\n",
    "            data.append([new_array, class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 565\n"
     ]
    }
   ],
   "source": [
    "load_data()\n",
    "print(\"No. of images: \" + str(len(data)))\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y_unsorted = []\n",
    "\n",
    "for features, label in data:\n",
    "    \n",
    "    X.append(features)\n",
    "    y_unsorted.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels,C):\n",
    "    mapping = {}\n",
    "    for i in range(C):\n",
    "        mapping[i]=i\n",
    "    one_hot_encode = []\n",
    "    for l in labels:\n",
    "        arr = list(np.zeros(C, dtype = int))\n",
    "        arr[mapping[l]] = 1\n",
    "        one_hot_encode.append(arr)\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = one_hot(y_unsorted,len(CATEGORIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X = (565, 64, 64, 3)\n",
      "Shape of y = (565, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Shape of X = \"+ str(X.shape))\n",
    "print(\"Shape of y = \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.T \n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 452\n",
      "Number of testing examples: m_test = 113\n",
      "Height/Width of each image: num_px = 64\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_set_x shape: (452, 64, 64, 3)\n",
      "train_set_y shape: (3, 452)\n",
      "test_set_x shape: (113, 64, 64, 3)\n",
      "test_set_y shape: (3, 113)\n"
     ]
    }
   ],
   "source": [
    "m_train = x_train.shape[0]\n",
    "m_test = x_test.shape[0]\n",
    "num_px = x_train.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(x_train.shape))\n",
    "print (\"train_set_y shape: \" + str(y_train.shape))\n",
    "print (\"test_set_x shape: \" + str(x_test.shape))\n",
    "print (\"test_set_y shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 452)\n",
      "train_set_y shape: (3, 452)\n",
      "test_set_x_flatten shape: (12288, 113)\n",
      "test_set_y shape: (3, 113)\n",
      "sanity check after reshaping: [177 187 197 168 177]\n"
     ]
    }
   ],
   "source": [
    "train_set_x_flatten = x_train.reshape(x_train.shape[0], -1).T\n",
    "test_set_x_flatten = x_test.reshape(x_test.shape[0], -1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(y_train.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(y_test.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set_x_flatten/255.\n",
    "x_test = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = x_train.shape[0]\n",
    "output_layer = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYCrMOuccJmt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTsIwkOUfP3h"
   },
   "outputs": [],
   "source": [
    "def init_params(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * (np.sqrt(2. / layer_dims[l-1]))\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :\n",
    "\n",
    "    L = len(parameters) // 2 \n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "\n",
    "        v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "        s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roz7tnESicfO"
   },
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Irs5R29uiose"
   },
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "  \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shMZanw5pBHm"
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \n",
    "    A = 1 / (1+np.exp(-Z))\n",
    "    cache = Z \n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bE-mfy-fp1Pa"
   },
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1 - s)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lG7fAaB8iz3I"
   },
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    \n",
    "    e_x = np.exp(Z - np.max(Z))\n",
    "    A = e_x / e_x.sum(axis=0, keepdims=True)\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8qGhEoEG7vT"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(Z):\n",
    "    \n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZJ02w-3iXjv"
   },
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \n",
    "    Z = W.dot(A) + b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPO4l__UhgC0"
   },
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        \n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        \n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    if activation == \"softmax\":\n",
    "        \n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqmA7DD0gqQT"
   },
   "outputs": [],
   "source": [
    "def forwardpass(X, parameters):\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "  \n",
    "    for l in range(1, L):\n",
    "        \n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters[\"b\" + str(l)], activation=\"relu\")\n",
    "        caches.append(cache)\n",
    "  \n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], activation=\"softmax\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y, AL):\n",
    "    \n",
    "    cost = -np.mean(Y * np.log(AL + 1e-8))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZJeEcq7od43"
   },
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    n = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./n * np.dot(dZ, A_prev.T)\n",
    "    db = 1./n * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-b-iYkz4n7QE"
   },
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \n",
    "    linear_cache, activation_cache = cache\n",
    "  \n",
    "    if activation == \"relu\":\n",
    "        \n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        \n",
    "    if activation == \"sigmoid\":\n",
    "        \n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        \n",
    "        dZ = dA\n",
    "  \n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SycGYYdFkgWZ"
   },
   "outputs": [],
   "source": [
    "def backwardpass(AL, Y, caches):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    n = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    dAL = AL - Y\n",
    "    curr_cache = caches[L-1]\n",
    "    \n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, curr_cache, activation=\"softmax\")\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        \n",
    "        curr_cache = caches[l]\n",
    "        dA_prev, dW, db = linear_activation_backward(grads[\"dA\" + str(l+1)], curr_cache, activation = \"relu\")\n",
    "        \n",
    "        grads[\"dA\" + str(l)] = dA_prev\n",
    "        grads[\"dW\" + str(l + 1)] = dW\n",
    "        grads[\"db\" + str(l + 1)] = db \n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IqWdqTgoyJW"
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1,L+1):\n",
    "        \n",
    "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)]\n",
    "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "\n",
    "    L = len(parameters) // 2                 \n",
    "    v_corrected = {}                         \n",
    "    s_corrected = {}                         \n",
    "    \n",
    "    for l in range(L):\n",
    "\n",
    "        v[\"dW\" + str(l+1)] = beta1*v[\"dW\" + str(l+1)] + (1-beta1)*grads['dW' + str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1*v[\"db\" + str(l+1)] + (1-beta1)*grads['db' + str(l+1)]\n",
    "\n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)]/(1-np.power(beta1,t))\n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)]/(1-np.power(beta1,t))\n",
    "\n",
    "        s[\"dW\" + str(l+1)] = beta2*s[\"dW\" + str(l+1)]+(1-beta2)*np.power(grads['dW' + str(l+1)],2)\n",
    "        s[\"db\" + str(l+1)] = beta2*s[\"db\" + str(l+1)]+(1-beta2)*np.power(grads['db' + str(l+1)],2)\n",
    "\n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1-np.power(beta2,t))\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1-np.power(beta2,t))\n",
    "\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)]-learning_rate*v_corrected[\"dW\" + str(l+1)]/np.sqrt(s_corrected[\"dW\" + str(l+1)] +epsilon)\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*v_corrected[\"db\" + str(l+1)]/np.sqrt(s_corrected[\"db\" + str(l+1)]+epsilon)\n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7jIXGl9dWNA"
   },
   "outputs": [],
   "source": [
    "def model(X, Y, layer_dims, learning_rate = 0.001, epochs = 5, print_cost = True):\n",
    "    \n",
    "    costs = []\n",
    "    t = 0\n",
    "    \n",
    "    parameters = init_params(layer_dims)\n",
    "    v, s = initialize_adam(parameters)\n",
    "    \n",
    "    \n",
    "    for i in range(epochs):\n",
    "        AL, caches = forwardpass(X, parameters)\n",
    "        cost = compute_cost(Y, AL) \n",
    "        grads = backwardpass(AL, Y, caches)\n",
    "        #parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        t = t + 1\n",
    "        parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8)\n",
    "\n",
    "        if print_cost and i % 10 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "        if i % 5 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per 10s)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "lw8J0HgwpJ-5",
    "outputId": "093ceb3f-e8b6-4abd-acaa-46e1e33808c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.363032\n",
      "Cost after iteration 10: 0.911486\n",
      "Cost after iteration 20: 0.873950\n",
      "Cost after iteration 30: 0.418649\n",
      "Cost after iteration 40: 0.285002\n",
      "Cost after iteration 50: 0.241900\n",
      "Cost after iteration 60: 0.215782\n",
      "Cost after iteration 70: 0.198332\n",
      "Cost after iteration 80: 0.184581\n",
      "Cost after iteration 90: 0.173311\n",
      "Cost after iteration 100: 0.162919\n",
      "Cost after iteration 110: 0.152628\n",
      "Cost after iteration 120: 0.142342\n",
      "Cost after iteration 130: 0.132285\n",
      "Cost after iteration 140: 0.122482\n",
      "Cost after iteration 150: 0.113019\n",
      "Cost after iteration 160: 0.103961\n",
      "Cost after iteration 170: 0.095370\n",
      "Cost after iteration 180: 0.087296\n",
      "Cost after iteration 190: 0.079768\n",
      "Cost after iteration 200: 0.072805\n",
      "Cost after iteration 210: 0.066408\n",
      "Cost after iteration 220: 0.060559\n",
      "Cost after iteration 230: 0.055236\n",
      "Cost after iteration 240: 0.050407\n",
      "Cost after iteration 250: 0.046037\n",
      "Cost after iteration 260: 0.042089\n",
      "Cost after iteration 270: 0.038525\n",
      "Cost after iteration 280: 0.035321\n",
      "Cost after iteration 290: 0.032436\n",
      "Cost after iteration 300: 0.029836\n",
      "Cost after iteration 310: 0.027490\n",
      "Cost after iteration 320: 0.025370\n",
      "Cost after iteration 330: 0.023451\n",
      "Cost after iteration 340: 0.021716\n",
      "Cost after iteration 350: 0.020141\n",
      "Cost after iteration 360: 0.018710\n",
      "Cost after iteration 370: 0.017408\n",
      "Cost after iteration 380: 0.016220\n",
      "Cost after iteration 390: 0.015138\n",
      "Cost after iteration 400: 0.014161\n",
      "Cost after iteration 410: 0.013281\n",
      "Cost after iteration 420: 0.012487\n",
      "Cost after iteration 430: 0.011768\n",
      "Cost after iteration 440: 0.011114\n",
      "Cost after iteration 450: 0.010516\n",
      "Cost after iteration 460: 0.009969\n",
      "Cost after iteration 470: 0.009470\n",
      "Cost after iteration 480: 0.009010\n",
      "Cost after iteration 490: 0.008583\n",
      "Cost after iteration 500: 0.008190\n",
      "Cost after iteration 510: 0.007829\n",
      "Cost after iteration 520: 0.007488\n",
      "Cost after iteration 530: 0.007179\n",
      "Cost after iteration 540: 0.006886\n",
      "Cost after iteration 550: 0.006613\n",
      "Cost after iteration 560: 0.006364\n",
      "Cost after iteration 570: 0.006122\n",
      "Cost after iteration 580: 0.005901\n",
      "Cost after iteration 590: 0.005697\n",
      "Cost after iteration 600: 0.005495\n",
      "Cost after iteration 610: 0.005309\n",
      "Cost after iteration 620: 0.005135\n",
      "Cost after iteration 630: 0.004972\n",
      "Cost after iteration 640: 0.004817\n",
      "Cost after iteration 650: 0.004673\n",
      "Cost after iteration 660: 0.004533\n",
      "Cost after iteration 670: 0.004402\n",
      "Cost after iteration 680: 0.004276\n",
      "Cost after iteration 690: 0.004161\n",
      "Cost after iteration 700: 0.004045\n",
      "Cost after iteration 710: 0.003938\n",
      "Cost after iteration 720: 0.003839\n",
      "Cost after iteration 730: 0.003740\n",
      "Cost after iteration 740: 0.003647\n",
      "Cost after iteration 750: 0.003562\n",
      "Cost after iteration 760: 0.003476\n",
      "Cost after iteration 770: 0.003395\n",
      "Cost after iteration 780: 0.003319\n",
      "Cost after iteration 790: 0.003244\n",
      "Cost after iteration 800: 0.003175\n",
      "Cost after iteration 810: 0.003106\n",
      "Cost after iteration 820: 0.003042\n",
      "Cost after iteration 830: 0.002978\n",
      "Cost after iteration 840: 0.002921\n",
      "Cost after iteration 850: 0.002861\n",
      "Cost after iteration 860: 0.002808\n",
      "Cost after iteration 870: 0.002752\n",
      "Cost after iteration 880: 0.002703\n",
      "Cost after iteration 890: 0.002652\n",
      "Cost after iteration 900: 0.002608\n",
      "Cost after iteration 910: 0.002558\n",
      "Cost after iteration 920: 0.002514\n",
      "Cost after iteration 930: 0.002472\n",
      "Cost after iteration 940: 0.002429\n",
      "Cost after iteration 950: 0.002391\n",
      "Cost after iteration 960: 0.002350\n",
      "Cost after iteration 970: 0.002313\n",
      "Cost after iteration 980: 0.002278\n",
      "Cost after iteration 990: 0.002241\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_dims = [input_layer, 24, output_layer]\n",
    "parameters = model(x_train, y_train, layer_dims, learning_rate = 0.02, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4oOLvEMV5D6"
   },
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \n",
    "    predictions, caches = forwardpass(X, parameters)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(X ,y):\n",
    "    \n",
    "    predictions = predict(X, y, parameters)\n",
    "\n",
    "    y_hat = np.argmax(predictions, axis = 0)\n",
    "    y_label = np.argmax(y, axis = 0)\n",
    "\n",
    "    return y_hat, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.77876106194691 %\n"
     ]
    }
   ],
   "source": [
    "y_hat, y_label = make_pred(x_train, y_train)\n",
    "\n",
    "score = accuracy_score(y_label, y_hat)\n",
    "\n",
    "print(\"Training accuracy: \" + str(score * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 54.86725663716814 %\n"
     ]
    }
   ],
   "source": [
    "y_hat, y_label = make_pred(x_test, y_test)\n",
    "\n",
    "score = accuracy_score(y_label, y_hat)\n",
    "\n",
    "print(\"Training accuracy: \" + str(score * 100) + \" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNB/VofgpXgjOfH0NjVcG2I",
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "MNIST Softmax Classifier",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
